{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7affca-7de4-426f-a990-575f1340e922",
   "metadata": {},
   "source": [
    "<h1>Part 08 : Image Processing Basics</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aea0596-83de-41c3-af27-94ce54305871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import glob as gb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caea792-802b-44ca-ad37-3f99b81bc286",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>OpenCV Library</h2>\n",
    "<h7>OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library. OpenCV was built to provide a common infrastructure for computer vision applications and to accelerate the use of machine perception in the commercial products. Being an Apache 2 licensed product, OpenCV makes it easy for businesses to utilize and modify the code.</h7>\n",
    "<a href = \"https://opencv.org/about/\">Read more</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f8a32f-7716-46fa-8221-d8b21beb75fc",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Glob library</h2>\n",
    "<h7>The glob module is a useful part of the Python standard library. glob (short for global) is used to return all file paths that match a specific pattern.</h7>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61977769-192f-4300-ba79-3aa9a06db7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pics\\\\2 (4).png',\n",
       " 'Pics\\\\ax.png',\n",
       " 'Pics\\\\bike.jpg',\n",
       " 'Pics\\\\color_dance.jpg',\n",
       " 'Pics\\\\combined.png',\n",
       " 'Pics\\\\gairls.jpg',\n",
       " 'Pics\\\\HSV_ColorSpace.jpg',\n",
       " 'Pics\\\\HSV_ColorSpace2.jpg',\n",
       " 'Pics\\\\rainbow.png']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = gb.glob('Pics/*.*')\n",
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52dc5f4d-efc7-4862-b7fe-7866e0b392cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dimensions: (520, 780, 3)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"Pics/bike.jpg\")\n",
    "\n",
    "print(f\"Image dimensions: {image.shape}\")     # print (height, width, number of channels)\n",
    "# 3-channel : BGR ==> Default mode in OpenCV is BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98aca189-d1fa-4b90-bda9-c1cc79cb73c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel value at (100, 200): [183 169 157]\n"
     ]
    }
   ],
   "source": [
    "# Access a specific pixel (e.g., row 100, column 200)\n",
    "pixel_value = image[100, 200] \n",
    "print(f\"Pixel value at (100, 200): {pixel_value}\")\n",
    "# This code snippet retrieves the pixel value at coordinates (100, 200) from the image using array indexing in OpenCV.\n",
    "# In OpenCV, images are represented as NumPy arrays.\n",
    "# This indicates that the pixel at coordinates (100, 200) has intensity values of \n",
    "# 183 for the Blue channel, 169 for the Green channel, and 157 for the Red channel.\n",
    "\n",
    "# if Blue = Green = Red =  0  ==> Color : Black\n",
    "# if Blue = Green = Red = 255 ==> Color : White"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa5544a8-ba34-4bf9-8217-05080699b2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183, 169, 157)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[100, 200][0], image[100, 200][1], image[100, 200][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d151a735-567d-4cb0-b2ab-039f81b2497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the Blue channel\n",
    "blue = image[..., 0]\n",
    "# This command extracts the blue channel of the image. In OpenCV, color images are typically represented in the BGR (Blue, Green, Red) color space, \n",
    "# so the blue channel corresponds to the first channel (index 0) of the image array.\n",
    "# Access the Green channel\n",
    "green = image[..., 1]\n",
    "# Access the Red channel\n",
    "red = image[..., 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f08fa82-1a32-49d3-a211-8f46dd776894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520, 780)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a4e9de2-5a66-4bd4-8db1-525fbe729fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(780,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ea9d257-c4c3-4f05-984f-679fb447be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the color channels separately (optional)\n",
    "cv2.imshow(\"Blue Channel\", blue)\n",
    "cv2.imshow(\"Green Channel\", green)\n",
    "cv2.imshow(\"Red Channel\", red)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "829b9278-fc6e-4983-af48-ca1499167f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Image\n",
    "img = cv2.imread('Pics/bike.jpg', 0)     # mode: gray\n",
    "# img = cv2.imread('Pics/bike.jpg', 1)     # mode: colorful\n",
    "cv2.imshow('Pic', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d257b82d-2280-4c40-8280-83852c1b55a5",
   "metadata": {},
   "source": [
    "<h2>Resize Image</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf6490c-1552-4517-8fae-2ace5053ed37",
   "metadata": {},
   "source": [
    "<h7 align = 'center'>This is useful for increase of dataset (Data Augmentation Step)</h7>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6676d3cb-d379-48ff-b5c8-d712b2897c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Pics/astronaut.jpg')\n",
    "print('Main Image coordinate:', img.shape)\n",
    "cv2.imshow('Pic_main', img)\n",
    "\n",
    "for i in range(3):\n",
    "    img = img[::2, ::2, :]\n",
    "#This command resizes the image by reducing its dimensions to half along both the height and width axes, while keeping all color channels intact\n",
    "\n",
    "    cv2.imshow(f'Pic_resize {i}', img)\n",
    "    print(f'Resize {i} image coordinate:', img.shape)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42c77cd7-9a76-46b7-a0eb-d913818adbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 62.5 ms\n",
      "Wall time: 1.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "img = cv2.imread('Pics/bike.jpg', 1)\n",
    "img = cv2.resize(img, (500, 500))\n",
    "cv2.imshow('img_resized', img)\n",
    "cv2.setWindowProperty('img_resized', cv2.WND_PROP_TOPMOST, 1)\n",
    "# This command is used in OpenCV to set window properties, particularly to make a window appear as the topmost window (on top of all other windows).\n",
    "# Parameter 01 ('img_resized'): This is the name of the window whose property is being set.\n",
    "# Parameter 02 (cv2.WND_PROP_TOPMOST) : This is a flag that indicates the property being set. In this case, it's used to make the window topmost.\n",
    "# Parameter 03 (1) : This value indicates the value to be set for the specified property. In this case, 1 typically means that the window should be made topmost.\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5be1a4ae-09b9-4a86-a12f-2295ae56adc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "638cf2fa-d34a-4613-bd43-41282d4d5868",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img[:, ::3, :]\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57621b26-0619-4f62-a632-c47bbf43ddbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99d2dda3-883d-4d44-9d47-d730df6d3334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9719cf35-a4f1-4159-8f38-efc939907cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add01404-f904-4126-a72b-dbfd994ea0b8",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Read Images from Webcam</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e16bc-1b01-4c10-b492-b39d638ebaa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)     # 0: the built-in camera on your laptop, 1: External webcam are connected to your system.\n",
    "i = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    # ret: status of read or not read\n",
    "    # frame: picture\n",
    "    print(\"ret:\", ret)\n",
    "    print(\"frame:\", frame)\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture frame\")\n",
    "        break\n",
    "    cv2.imshow('one', frame)\n",
    "    print(\"i:\", i)\n",
    "    i += 1\n",
    "\n",
    "    q = cv2.waitKey(1)     # return Asci Code of key\n",
    "    if q == ord('q'):      # compaer Asci Code of 'q'\n",
    "        break\n",
    "cap.release()     # Close the window \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24938ac8-aac4-4d45-a23f-d5853541b780",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Write Persian font on Camera image</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24bd6b9f-9921-4594-b0b3-cee2cbdd029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "from PIL import ImageFont\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9892e6a4-d9ba-485e-81ae-7d2b29b77b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt2fa(txt):\n",
    "    reshaped_text = arabic_reshaper.reshape(txt)\n",
    "    farsi_text = get_display(reshaped_text)\n",
    "    return farsi_text\n",
    "\n",
    "def cvt_cv2_frame_2_pil_image(frame):     # Conver to PIL\n",
    "    color_coverted = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pil_image = Image.fromarray(color_coverted)\n",
    "    return pil_image\n",
    "\n",
    "def cvt_pil_image_2_cv2_frame(pil_image):\n",
    "    nimg = np.array(pil_image)\n",
    "    frame = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n",
    "    return frame\n",
    "\n",
    "def put_persian_text(txt, pil_image, w_h = (0, 0)):\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "    bidi_text = txt2fa(txt)\n",
    "    font_path = 'H:\\SoftWares\\Fonts\\iransans.ttf'\n",
    "    arabic_font = ImageFont.truetype(font_path, 20)\n",
    "    draw.text(w_h, bidi_text, (255, 0, 255), font = arabic_font)\n",
    "    return pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6f128a0-7c43-4bae-8e2c-60201e210eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "# input('#Check font file is exist?')\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    pil_image = cvt_cv2_frame_2_pil_image(frame)     # Conver to PIL\n",
    "    text = \"سلام دنیا. من دارم پردازش تصویر یاد میگیرم\"\n",
    "    pil_image = put_persian_text(text, pil_image, (10, 150))\n",
    "\n",
    "    frame = cvt_pil_image_2_cv2_frame(pil_image)\n",
    "    cv2.imshow('Original', frame)\n",
    "\n",
    "    q = cv2.waitKey(1)\n",
    "    if q == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "print(ret)\n",
    "cv2.destroyAllWindows()        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ea0809-6f40-4b8e-8b85-1abf167c4fba",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Image Data Type and Value Manipulation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8a0f85c-573c-49be-af35-776282e42595",
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = 512, 512\n",
    "data = np.zeros((h, w, 3), dtype = np.uint8)\n",
    "data[0 : 250, 0 : 250, :] = [0, 0, 255]           # Red\n",
    "data[0 : 250, 262 : 513, :] = [0 , 255, 0]        # Green\n",
    "data[262 : 513, 0 : 250, :] = [255, 0, 0]         # Blue\n",
    "data[262 : 513, 262 : 513, :] = [128, 0, 128]     # Purple\n",
    "data[250 : 262, 250 : 262, :] = [255, 255, 255]   # White \n",
    "\n",
    "cv2.imshow('MyColorPic', data)\n",
    "cv2.setWindowProperty('MyColorPic', cv2.WND_PROP_TOPMOST, 1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d26a26b7-0bc5-4d13-9c8b-a6027142843e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0   0 255]\n",
      "  [  0   0 255]\n",
      "  [  0   0 255]\n",
      "  ...\n",
      "  [  0 255   0]\n",
      "  [  0 255   0]\n",
      "  [  0 255   0]]\n",
      "\n",
      " [[  0   0 255]\n",
      "  [  0   0 255]\n",
      "  [  0   0 255]\n",
      "  ...\n",
      "  [  0 255   0]\n",
      "  [  0 255   0]\n",
      "  [  0 255   0]]\n",
      "\n",
      " [[  0   0 255]\n",
      "  [  0   0 255]\n",
      "  [  0   0 255]\n",
      "  ...\n",
      "  [  0 255   0]\n",
      "  [  0 255   0]\n",
      "  [  0 255   0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255   0   0]\n",
      "  [255   0   0]\n",
      "  [255   0   0]\n",
      "  ...\n",
      "  [128   0 128]\n",
      "  [128   0 128]\n",
      "  [128   0 128]]\n",
      "\n",
      " [[255   0   0]\n",
      "  [255   0   0]\n",
      "  [255   0   0]\n",
      "  ...\n",
      "  [128   0 128]\n",
      "  [128   0 128]\n",
      "  [128   0 128]]\n",
      "\n",
      " [[255   0   0]\n",
      "  [255   0   0]\n",
      "  [255   0   0]\n",
      "  ...\n",
      "  [128   0 128]\n",
      "  [128   0 128]\n",
      "  [128   0 128]]]\n",
      "\n",
      "Image Coordinate: (512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(\"\\nImage Coordinate:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f82a63f-2ce8-4766-9b3d-6b85ffc125d4",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Split BGR Layers</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdd3b8ae-a8ba-4861-bda3-69bf5ead625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(r'Pics/color_dance.jpg', 1)     # The r before the string denotes a raw string literal in Python, which is often used for file paths to avoid interpreting special characters.\n",
    "\n",
    "B, G, R = cv2.split(image)\n",
    "# Corresponding channels are seperated\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.imshow('Blue', B)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.imshow('Green', G)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.imshow('Red', R)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aad9e3-af1e-4dd8-b9cd-1f5d74398506",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Merge BGR Layers</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "727b40b5-0978-400d-a4f9-fb7093115baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(r'Pics/bike.jpg', 1)\n",
    "cv2.imshow('Image_bike', image)\n",
    "cv2.waitKey()\n",
    "\n",
    "img_merged1 = cv2.merge((B, G, R))\n",
    "cv2.imshow('Img_merged_BGR', img_merged1)\n",
    "cv2.waitKey()\n",
    "\n",
    "img_merged2 = cv2.merge((R, G, B))\n",
    "cv2.imshow('Img_merged_RGB', img_merged2)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02a72de-d377-4f18-8935-9d86696fe58f",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Save Image</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a748cbc4-644c-4db3-848a-1e0193f85a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image written sucess? True True\n"
     ]
    }
   ],
   "source": [
    "status1 = cv2.imwrite('Pics/Img_merged_BGR.jpg', img_merged1)\n",
    "status2 = cv2.imwrite('Pics/Img_merged_RGB.jpg', img_merged2)\n",
    "print('Image written sucess?', status1, status2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d981f6-99d3-4f71-896d-5ce5d2a4f5a8",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Combine two images together</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50e1b528-01d8-4823-a30d-8e494c2d43e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = cv2.imread(r'Pics/bike.jpg', 1)\n",
    "overlay = cv2.imread(r'Pics/girls.jpg', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c037192d-ad8a-4d86-85ab-e15cef742741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520, 780, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d9df921-3a61-4801-a68b-5eae3deff069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1163, 934, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlay.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a73e72dc-797b-4bc5-99eb-324810c0f9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = cv2.resize(overlay, dsize = (780, 520))     # Resize the larger image (overlay) to the smaller one (background)\n",
    "added_image = cv2.addWeighted(background, 0.4, overlay, 0.2, 0)\n",
    "# This command blends two images together using the weighted addition method provided by OpenCV's addWeighted() function.\n",
    "# Parameter4 (0) : It's often used for brightness adjustments\n",
    "cv2.imwrite('Pics/Overlay.png', added_image)\n",
    "cv2.imshow('Overlay', added_image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1ea4e0-138b-4b4f-90fa-f105d55a8a79",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Color Space Conversion</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006d8fdd-c68a-4869-851a-8821a55f1cb6",
   "metadata": {},
   "source": [
    "<h2>HSV Color Space</h2>\n",
    "\n",
    "<h4>Hue(H) range is [0,179] :</h4> \n",
    "<h8>\n",
    "Hue represents the dominant wavelength of light and corresponds to the color itself. In other words, it indicates the type of color (red, green, blue, etc.). Hue is measured in degrees, typically ranging from 0 to 360. However, in OpenCV, the range is typically normalized to 0-179 to fit within an 8-bit integer.</h8>\n",
    "\n",
    "<h4>Saturation range is [0,255]:</h4>\n",
    "<h8>\n",
    "Saturation refers to the intensity or purity of the color. It represents the amount of gray in proportion to the hue, measured as a percentage. A saturation value of 0 results in a shade of gray (unsaturated), while a value of 100% (or 255 in the case of OpenCV) represents a fully saturated color.</h8>\n",
    "\n",
    "<h4>Value range is [0,255] : </h4>\n",
    "<h8>\n",
    "Value represents the brightness or lightness of the color. It indicates how much light is emitted by the color. A value of 0 represents black (no light), while the maximum value (255 in OpenCV) represents the brightest possible color.</h8>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3b13bb7-2660-4875-8769-d2cbf484b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(r'Pics/bike.jpg')\n",
    "image_cvt = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "# HSV stands for Hue, Saturation, and Value, and it represents a color space used to describe colors in terms of their hue, saturation, and brightness or value.\n",
    "cv2.imshow('Original_BGR', image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.imshow('Image_HSV', image_cvt)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9821434-8fd1-4a8d-b3f4-5b711e2588d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Pics/HSV_ColorSpace.jpg', 1)\n",
    "rainbow = cv2.imread('Pics/rainbow.png', 1)\n",
    "\n",
    "img_resized = cv2.resize(img, dsize = (500, 500))\n",
    "rainbow_rs = cv2.resize(rainbow, dsize = (500, 500))\n",
    "\n",
    "cv2.imshow('HSV_ColorSpace', img_resized)\n",
    "cv2.imshow('Rainbow', rainbow_rs)\n",
    "\n",
    "\n",
    "cv2.setWindowProperty('Rainbow', cv2.WND_PROP_TOPMOST, 1)\n",
    "cv2.setWindowProperty('HSV_ColorSpace', cv2.WND_PROP_TOPMOST, 1)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea93324-6bab-4b6d-9ead-57c4ccd34f75",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Image Layers in Color Space (HSV)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "81c62cf7-8fd2-40b6-bf2f-3ed3371a348d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pics\\\\2 (4).png',\n",
       " 'Pics\\\\astronaut.jpg',\n",
       " 'Pics\\\\ax.png',\n",
       " 'Pics\\\\bike.jpg',\n",
       " 'Pics\\\\bike_save.jpg',\n",
       " 'Pics\\\\color_dance.jpg',\n",
       " 'Pics\\\\combined.png',\n",
       " 'Pics\\\\download.jpg',\n",
       " 'Pics\\\\girls.jpg',\n",
       " 'Pics\\\\HSV_ColorSpace.jpg',\n",
       " 'Pics\\\\HSV_ColorSpace2.jpg',\n",
       " 'Pics\\\\Img_merged_BGR.jpg',\n",
       " 'Pics\\\\Img_merged_RGB.jpg',\n",
       " 'Pics\\\\Overlay.png',\n",
       " 'Pics\\\\rainbow.png']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = gb.glob('Pics/*.*')\n",
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8429d75e-1d14-4f51-a355-a65800d3b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bgr = cv2.imread('Pics/color_dance.jpg')\n",
    "img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "cv2.imshow('Original', img_bgr)\n",
    "cv2.waitKey()\n",
    "cv2.imshow('img_hsv', img_hsv)\n",
    "cv2.waitKey()\n",
    "\n",
    "H, S, V = cv2.split(img_hsv)\n",
    "\n",
    "cv2.imshow('H', H)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.imshow('S', S)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.imshow('V', V)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59aa8967-fa37-4201-8682-31dd82d1e648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H.max(): 179\n",
      "H.min(): 0\n"
     ]
    }
   ],
   "source": [
    "print(\"H.max():\", H.max())\n",
    "print(\"H.min():\", H.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ab8257f-8a97-4318-891c-e0c97a0da1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S.max(): 255\n",
      "S.min(): 0\n"
     ]
    }
   ],
   "source": [
    "print(\"S.max():\", S.max())\n",
    "print(\"S.min():\", S.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b75d8924-1b89-40b8-9062-b742df7bacda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V.max(): 255\n",
      "V.min(): 0\n"
     ]
    }
   ],
   "source": [
    "print(\"V.max():\", V.max())\n",
    "print(\"V.min():\", V.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcab45e-d9bc-4b9a-8998-a08eb1d0c2f9",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Separate a color</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df595166-508c-4857-b928-701cd65ac387",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bgr = cv2.imread('Pics/red_dress.jpg', 1)\n",
    "img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "low_red = np.array([161, 155, 84])\n",
    "high_red = np.array([179, 255, 255])\n",
    "\n",
    "red_mask = cv2.inRange(img_hsv, low_red, high_red)\n",
    "\n",
    "cv2.imshow('Original', img_bgr)\n",
    "cv2.imshow('Red_mask', red_mask)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0a7e9bce-98fb-48e9-94d1-152a788b9bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520, 780)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3a0aa47b-8daa-47c4-9b44-f5df960d517c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520, 780, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_bgr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dffe9003-2107-4fc9-85b0-a6c497f39592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520, 780, 3)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_hsv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01cfa3c9-9ed1-4f5e-9966-b5a63df6ff1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "071ca434-2f14-4b23-8d3e-d868bb2d0749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_mask.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaae24aa-7e70-4ad5-8736-306e39612e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_mask.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc07c8a-e6ad-4d38-8093-8fbfb351903f",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Rotate Image</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e238c13-782a-4180-a7d0-fff78bf15a4d",
   "metadata": {},
   "source": [
    "<h4>Mehtod_01 : Rotate with Fixed angles</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e19b3e5-dbd3-4e2c-92c7-7abce0471c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(520, 780, 3)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('Pics/bike.jpg')\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa6145be-c1b1-4424-8b50-ba818df66fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rt180 = cv2.rotate(img, cv2.ROTATE_180)\n",
    "img_rt90 = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Img_Rotated_180', img_rt180)\n",
    "cv2.imshow('Img_Rotated_90', img_rt90)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a873f763-9f13-4415-98c1-0e4414066f14",
   "metadata": {},
   "source": [
    "<h4>Mehtod_02 : Rotate with Desired angles, Center and Scale</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "18d1921d-10fb-4199-a1f2-cd78cd8195ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.70710678   0.70710678 -69.61940777]\n",
      " [ -0.70710678   0.70710678 351.92388155]]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('Pics/bike.jpg')\n",
    "(h, w) = img.shape[:2]\n",
    "# get image height, width\n",
    "\n",
    "center = (w / 2, h / 2)\n",
    "\n",
    "scale_1 = 1     # To resize image\n",
    "scale_2 = 2\n",
    "\n",
    "M45 = cv2.getRotationMatrix2D(center, 45, scale)\n",
    "print(M45)\n",
    "rotated45 = cv2.warpAffine(img, M45, (h, w))     # Rotate '45' degrees\n",
    "\n",
    "M110 = cv2.getRotationMatrix2D(center, 110, scale)\n",
    "rotated110 = cv2.warpAffine(img, M110, (h, w))     # Rotate '110' degrees\n",
    "\n",
    "M_45 = cv2.getRotationMatrix2D(center, -45, scale_2)\n",
    "rotated_45 = cv2.warpAffine(img, M_45, (h, w))     # Rotate '-45' degrees\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('img_rotated_45', rotated45)\n",
    "cv2.imshow('img_rotated_110', rotated110)\n",
    "cv2.imshow('img_rotated_-45', rotated_45)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55ca242-3d5a-496a-b73b-25dafe8a9759",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Draw a Circle</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3b7b017-e233-42b9-a23d-025737cabe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Pics/bike.jpg', 1)\n",
    "cv2.circle(img, (100, 100), 100, (255, 255, 0),-1)     # (Image, Center, Radius, Color, Fill inside (-1) or not (thickness from 0 to ...))\n",
    "\n",
    "cv2.imshow('Circle image', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b352409-360f-46af-8165-a161bc262e34",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Draw a Rectangle</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1e320c01-9899-4ef0-bb1f-62b0cfd26bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Pics/bike.jpg')\n",
    "cv2.rectangle(img, (15, 25), (250, 150), (0, 255, 255), 5)     #(Image, Point_1, Point_2 (Diameter), Color, Fill inside (-1) or not (thickness from 0 to ...))\n",
    "\n",
    "cv2.imshow('Rectangle', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfce5986-2518-4ee0-bc78-711c59a04a28",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Draw Poly Lines</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "077ad6cd-7af7-479f-aa44-94c40cf4cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Pics/bike.jpg')\n",
    "\n",
    "pts = np.array([[100, 50], [200, 300], [500, 100], [700, 200]], np.int32)\n",
    "\n",
    "cv2.polylines(img, [pts], True, (255, 0, 255), 4)     # (Image, Points, Close or Open, Color, Tickness)\n",
    "# cv2.polylines(img, [pts], False, (255, 0, 255), 4)\n",
    "\n",
    "cv2.imshow('Image_polylines', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a3c0ed-b431-4630-9910-6586c1a01e4c",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Put Text</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f9444a2d-bbc2-43bb-a09f-c52399a05e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "img = cv2.imread('Pics/girls.jpg')\n",
    "txt = 'I love DataScience and AI :)'\n",
    "cv2.putText(img, txt, (10, 50), font, 1, (0, 0, 255), 2)\n",
    "\n",
    "cv2.imshow('Image_text', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7e8aae-bc9f-44f3-aac1-fa65593c7499",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Jump over the image data & Generate a new image</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeacedab-b24e-4ef5-916c-22cff051a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Pics/bike.jpg')\n",
    "img_1 = img[::, ::5, :].copy()\n",
    "img_2 = img[::5, ::, :].copy()\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('NewImage1(resizedX)', img_1)\n",
    "cv2.imshow('NewImage2(resizedY)', img_2)\n",
    "\n",
    "cv2.setWindowProperty('Original', cv2.WND_PROP_TOPMOST, 1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2822e683-1285-46c5-ab0f-48d84c268db2",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Image Filtering</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4022e6-c2c9-45e4-81bc-2e305bc446bb",
   "metadata": {},
   "source": [
    "## Convolution filter\n",
    "##### It is a fundamental operation in image processing, and it's essential for tasks like blurring, sharpening, and edge detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "350e7790-03ad-46ea-a7a4-2ca980c32de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Pics/girls.jpg', 1)\n",
    "cv2.imshow('Original', img)\n",
    "cv2.setWindowProperty('Original', cv2.WND_PROP_TOPMOST, 1)\n",
    "\n",
    "kernel = np.ones((5, 5), np.float32) / 25\n",
    "# This is the convolution kernel that defines the filter's behavior. The kernel is a matrix that determines the weights applied to each pixel and its neighbors during the convolution operation.\n",
    "\n",
    "dst = cv2.filter2D(img, -1, kernel)     # -1 : This parameter indicates the depth of the output image. A value of -1 means the depth of the output image will be the same as the input image.\n",
    "# The command applies a 2D convolution filter to the image 'img' using the specified kernel.\n",
    "\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.setWindowProperty('dst', cv2.WND_PROP_TOPMOST, 1)\n",
    "\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96c91c42-643b-4bbe-9b2c-55253bc920b3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel:\n",
      "[[0.04 0.04 0.04 0.04 0.04]\n",
      " [0.04 0.04 0.04 0.04 0.04]\n",
      " [0.04 0.04 0.04 0.04 0.04]\n",
      " [0.04 0.04 0.04 0.04 0.04]\n",
      " [0.04 0.04 0.04 0.04 0.04]]\n",
      "\n",
      "[[[234 231 226]\n",
      "  [234 231 226]\n",
      "  [234 231 226]\n",
      "  ...\n",
      "  [230 222 209]\n",
      "  [230 222 209]\n",
      "  [230 222 209]]\n",
      "\n",
      " [[234 231 226]\n",
      "  [234 231 226]\n",
      "  [234 231 226]\n",
      "  ...\n",
      "  [230 222 209]\n",
      "  [230 222 209]\n",
      "  [230 222 209]]\n",
      "\n",
      " [[235 232 227]\n",
      "  [235 232 227]\n",
      "  [235 232 227]\n",
      "  ...\n",
      "  [231 223 210]\n",
      "  [231 223 210]\n",
      "  [231 223 210]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[133 158 178]\n",
      "  [129 154 174]\n",
      "  [121 147 164]\n",
      "  ...\n",
      "  [104 128 152]\n",
      "  [107 131 155]\n",
      "  [108 132 156]]\n",
      "\n",
      " [[122 147 167]\n",
      "  [120 145 165]\n",
      "  [116 142 159]\n",
      "  ...\n",
      "  [106 130 154]\n",
      "  [109 133 157]\n",
      "  [110 134 158]]\n",
      "\n",
      " [[114 139 159]\n",
      "  [113 138 158]\n",
      "  [112 138 155]\n",
      "  ...\n",
      "  [109 133 157]\n",
      "  [111 135 159]\n",
      "  [113 137 161]]]\n",
      "\n",
      "[[[234 231 226]\n",
      "  [235 232 227]\n",
      "  [235 232 227]\n",
      "  ...\n",
      "  [230 222 209]\n",
      "  [230 222 209]\n",
      "  [230 222 209]]\n",
      "\n",
      " [[235 232 227]\n",
      "  [235 232 227]\n",
      "  [235 232 227]\n",
      "  ...\n",
      "  [231 223 210]\n",
      "  [231 223 210]\n",
      "  [231 223 210]]\n",
      "\n",
      " [[235 232 227]\n",
      "  [235 232 227]\n",
      "  [235 232 227]\n",
      "  ...\n",
      "  [231 223 210]\n",
      "  [231 223 210]\n",
      "  [231 223 210]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[123 148 167]\n",
      "  [122 147 166]\n",
      "  [120 146 164]\n",
      "  ...\n",
      "  [106 130 154]\n",
      "  [107 131 155]\n",
      "  [107 131 155]]\n",
      "\n",
      " [[121 146 165]\n",
      "  [120 146 165]\n",
      "  [118 144 162]\n",
      "  ...\n",
      "  [105 129 153]\n",
      "  [107 131 155]\n",
      "  [107 131 155]]\n",
      "\n",
      " [[121 146 165]\n",
      "  [120 145 164]\n",
      "  [117 143 161]\n",
      "  ...\n",
      "  [105 129 153]\n",
      "  [107 131 155]\n",
      "  [108 132 156]]]\n"
     ]
    }
   ],
   "source": [
    "print('Kernel:')\n",
    "print(kernel)\n",
    "print()\n",
    "print(img)\n",
    "print()\n",
    "print(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cadd7c1-e4c0-4b52-96c7-b1e6a33778dd",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Low pass filters</h2>\n",
    "<h4 align = 'center'>The rate of change is low.</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9384015f-e521-42a0-a873-7876cad883ae",
   "metadata": {},
   "source": [
    "## Blur Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5e7567e-435f-49bd-b2da-6c9350e00ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Pics/girls.jpg')\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('CV2.blur Output', cv2.blur(img, (8, 8)))\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b81e3d-72b1-4f9d-9138-4ddac664ce5d",
   "metadata": {},
   "source": [
    "## Median Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b81dc0d-f88d-4187-8458-9f24e8394de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Pics/girls.jpg')\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('CV2.medianBlur Output', cv2.medianBlur(img, 5))\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52c0a24-7fcd-4774-b6fa-42c54242826d",
   "metadata": {},
   "source": [
    "## Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa73209a-ae9b-4240-b9bf-6efb309723f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Pics/girls.jpg')\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('CV2.GaussianBlur Output', cv2.GaussianBlur(img, (5, 5), cv2.BORDER_DEFAULT))\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e82366f-0da1-45fa-bbd6-d15ab6922d85",
   "metadata": {},
   "source": [
    "## Bilateral Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d708567-6558-4046-8906-4f94af456da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Pics/girls.jpg')\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('CV2.bilateralFilter Output', cv2.bilateralFilter(img, 5, 120, 120))\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b5eeda-ca68-47de-8592-0b9394c9e606",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Determining threshold limits</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7f71674-0915-4d66-998f-1d0a76532d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Pics/bike.jpg', 0)\n",
    "\n",
    "threshold = 100\n",
    "\n",
    "ret, thresh1 = cv2.threshold(img, threshold, 255, cv2.THRESH_BINARY)      # Binary Threshold\n",
    "ret, thresh2 = cv2.threshold(img, threshold, 255, cv2.THRESH_BINARY_INV)  # Binary Threshold Inverted\n",
    "ret, thresh3 = cv2.threshold(img, threshold, 255, cv2.THRESH_TRUNC)       # Truncated Threshold\n",
    "ret, thresh4 = cv2.threshold(img, threshold, 255, cv2.THRESH_TOZERO)      # Zero Threshold\n",
    "ret, thresh5 = cv2.threshold(img, threshold, 255, cv2.THRESH_TOZERO_INV)  # Zero Inverted\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Binary Threshold', thresh1)\n",
    "cv2.imshow('Binary Threshold Inverted', thresh2)\n",
    "cv2.imshow('Truncated Threshold', thresh3)\n",
    "cv2.imshow('Zero Threshold', thresh4)\n",
    "cv2.imshow('Zero Inverted', thresh5)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ba76e-430d-40fc-af8a-29b4c0a52c9f",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Adaptive Threshold</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a42a9c9-bb81-4548-bbd9-b56958b92be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Pics/bike.jpg')\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, th1 = cv2.threshold(img, 160, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "th2 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "th3 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Binary Threshold', th1)\n",
    "cv2.imshow('Mean Adaptive Threshold', th2)\n",
    "cv2.imshow('Gaussian Adaptive Threshold', th3)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4c6288-80ae-405c-8ac4-be1d19306543",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>High pass filters</h2>\n",
    "<h4 align = 'center'>The rate of change is high (In Borders)</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae12bf0-f2dd-4310-bcb4-6f31996f4e02",
   "metadata": {},
   "source": [
    "## Canny Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a167bae8-d016-440f-88b4-ee93f99fa0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Pics/bike.jpg')\n",
    "edges = cv2.Canny(img, 100, 80, True)\n",
    "\n",
    "cv2.imshow('Edge Detected Image', edges)\n",
    "cv2.imshow('Original', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bafc0aa-5c65-463e-9cf1-d34e26bd46a9",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Contouring</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778bcea8-bc1a-4ff0-9686-4483dfbcc48c",
   "metadata": {},
   "source": [
    "##### Contouring in image processing refers to the process of detecting and representing the boundaries of objects within an image. These boundaries are represented as a set of continuous curves or contours that enclose areas of similar intensity or color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef8d8f56-e844-4512-a249-69f826658e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Pics/bike.jpg')\n",
    "edged = cv2.Canny(image, 30, 100)\n",
    "# cv2.waitKey()\n",
    "\n",
    "contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow('Original', image)\n",
    "cv2.imshow('Canny Edges After Contouring', edged)\n",
    "\n",
    "cv2.drawContours(image, contours, -1, (0, 255, 0), 1)\n",
    "\n",
    "cv2.imshow('Contours', image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af50847b-9df7-4223-9772-042c928543ad",
   "metadata": {},
   "source": [
    "<h2 align = 'center'>Draw a Circle with Double Click</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c489912c-0efd-4084-944c-ab676d445826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EVENT_FLAG_ALTKEY', 'EVENT_FLAG_CTRLKEY', 'EVENT_FLAG_LBUTTON', 'EVENT_FLAG_MBUTTON', 'EVENT_FLAG_RBUTTON', 'EVENT_FLAG_SHIFTKEY', 'EVENT_LBUTTONDBLCLK', 'EVENT_LBUTTONDOWN', 'EVENT_LBUTTONUP', 'EVENT_MBUTTONDBLCLK', 'EVENT_MBUTTONDOWN', 'EVENT_MBUTTONUP', 'EVENT_MOUSEHWHEEL', 'EVENT_MOUSEMOVE', 'EVENT_MOUSEWHEEL', 'EVENT_RBUTTONDBLCLK', 'EVENT_RBUTTONDOWN', 'EVENT_RBUTTONUP']\n"
     ]
    }
   ],
   "source": [
    "mouse_events = [j for j in dir(cv2) if 'EVENT' in j]\n",
    "print(mouse_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "639d73e1-1f41-4eea-9044-a3c9cbb6f6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please Double Click in the Window\n"
     ]
    }
   ],
   "source": [
    "def draw_circle(event, x, y, flags, param):\n",
    "    if (event == cv2.EVENT_LBUTTONDBLCLK):\n",
    "        cv2.circle(img, (x, y), 50, (100, 0, 255), -1)     # (Image, Center, Radius, Color, Fill inside (-1) or not (thickness from 0 to ...))\n",
    "img = np.zeros((512, 512, 3), np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image', draw_circle)\n",
    "\n",
    "print(\"Please Double Click in the Window\")\n",
    "while(1):\n",
    "    cv2.imshow('image', img)\n",
    "    q = cv2.waitKey(1)\n",
    "    if q == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e002f06-a70f-47a6-9f92-24f0fee15212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f37ce-5808-4d9b-ad80-efe403c7f6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
